name: model_evaluation_import
description: |
  Imports a model evaluation artifact to an existing Vertex model with ModelService.ImportModelEvaluation
  For more details, see https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.models.evaluations
  Args:
    metrics (system.Metrics):
      Path of metrics generated from an evaluation component.
    classification_metrics (google.ClassificationMetrics):
      Path of classification metrics generated from a classification evaluation component.
    forecasting_metrics (google.ForecastingMetrics):
      Path of forecasting metrics generated from a forecasting evaluation component.
    regression_metrics (google.RegressionMetrics):
      Path of regression metrics generated from a regression evaluation component.
    explanation (Optional[system.Metrics]):
      Path for model explanation metrics generated from an evaluation component.
    model (google.VertexModel):
      Vertex model resource that will be the parent resource of the uploaded evaluation.
    problem_type (str):
      The problem type of the metrics being imported to the VertexModel.
        `classification`, `regression`, and `forecasting` are the currently supported problem types.
    display_name (str):
      The display name for the uploaded model evaluation resource.
inputs:
  - {name: metrics, type: Metrics, optional: True}
  - {name: classification_metrics, type: google.ClassificationMetrics, optional: True}
  - {name: forecasting_metrics, type: google.ForecastingMetrics, optional: True}
  - {name: regression_metrics, type: google.RegressionMetrics, optional: True}
  - {name: explanation, type: Metrics, optional: True}
  - {name: model, type: google.VertexModel}
  - {name: problem_type, type: String, optional: True}
  - {name: display_name, type: String, default: ''}
  - {name: dataset_path, type: String, default: ''}
  - {name: dataset_type, type: String, default: ''}
outputs:
- {name: gcp_resources, type: String}
implementation:
  container:
    image: gcr.io/ml-pipeline/google-cloud-pipeline-components:latest
    command: [python3, -u, -m, google_cloud_pipeline_components.container.experimental.evaluation.import_model_evaluation]
    args:
      - --metrics
      - {inputPath: metrics}
      - --metrics_explanation
      - "{{$.inputs.artifacts['metrics'].metadata['explanation_gcs_path']}}"
      - if:
        cond: {isPresent: classification_metrics}
        then:
        - --classification_metrics
        - {inputPath: classification_metrics}
      - if:
        cond: {isPresent: forecasting_metrics}
        then:
        - --forecasting_metrics
        - {inputPath: forecasting_metrics}
      - if:
        cond: {isPresent: regression_metrics}
        then:
        - --regression_metrics
        - {inputPath: regression_metrics}
      - if:
          cond: {isPresent: explanation}
          then:
          - --explanation
          - "{{$.inputs.artifacts['explanation'].metadata['explanation_gcs_path']}}"
      - if:
        cond: {isPresent: problem_type}
        then:
        - --problem_type
        - {inputValue: problem_type}
      - --display_name
      - {inputValue: display_name}
      - --dataset_path
      - {inputValue: dataset_path}
      - --dataset_type
      - {inputValue: dataset_type}
      - --pipeline_job_id
      - "{{$.pipeline_job_uuid}}"
      - --model_name
      - "{{$.inputs.artifacts['model'].metadata['resourceName']}}"
      - --gcp_resources
      - {outputPath: gcp_resources}
